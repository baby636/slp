
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      <link rel="shortcut icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.1.2, mkdocs-material-7.0.5">
    
    
      
        <title>Pytorch Lightning Bindings - slp Documentation</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.77f3fd56.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.7fa14f5b.min.css">
        
      
    
    
    
      
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&display=fallback">
        <style>:root{--md-text-font-family:"Roboto";--md-code-font-family:"Roboto Mono"}</style>
      
    
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    
      
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
      
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pytorch-lightning-bindings" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="slp Documentation" class="md-header__button md-logo" aria-label="slp Documentation">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            slp Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Pytorch Lightning Bindings
            
          </span>
        </div>
      </div>
    </div>
    <div class="md-header__options">
      
    </div>
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
      </label>
      
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" data-md-state="active" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
      </label>
      <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41z"/></svg>
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    




<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="slp Documentation" class="md-nav__button md-logo" aria-label="slp Documentation">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54z"/></svg>

    </a>
    slp Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        slp
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../get-started/" class="md-nav__link">
        Getting started
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../tuning/" class="md-nav__link">
        Hyperparameter tuning
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../config/" class="md-nav__link">
        Configuration
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../data-utils/" class="md-nav__link">
        Data manipulation
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Pytorch Lightning Bindings
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Pytorch Lightning Bindings
      </a>
      
        
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm" class="md-nav__link">
    slp.plbind.dm
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus" class="md-nav__link">
    PLDataModuleFromCorpus
  </a>
  
    <nav class="md-nav" aria-label="PLDataModuleFromCorpus">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.embeddings" class="md-nav__link">
    embeddings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.vocab_size" class="md-nav__link">
    vocab_size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.add_argparse_args" class="md-nav__link">
    add_argparse_args()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets" class="md-nav__link">
    PLDataModuleFromDatasets
  </a>
  
    <nav class="md-nav" aria-label="PLDataModuleFromDatasets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.add_argparse_args" class="md-nav__link">
    add_argparse_args()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.prepare_data" class="md-nav__link">
    prepare_data()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.test_dataloader" class="md-nav__link">
    test_dataloader()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.train_dataloader" class="md-nav__link">
    train_dataloader()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.val_dataloader" class="md-nav__link">
    val_dataloader()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.split_data" class="md-nav__link">
    split_data()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers" class="md-nav__link">
    slp.plbind.helpers
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger" class="md-nav__link">
    FixedWandbLogger
  </a>
  
    <nav class="md-nav" aria-label="FixedWandbLogger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger.finalize" class="md-nav__link">
    finalize()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits" class="md-nav__link">
    FromLogits
  </a>
  
    <nav class="md-nav" aria-label="FromLogits">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.compute" class="md-nav__link">
    compute()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.update" class="md-nav__link">
    update()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module" class="md-nav__link">
    slp.plbind.module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.AutoEncoderPLModule" class="md-nav__link">
    AutoEncoderPLModule
  </a>
  
    <nav class="md-nav" aria-label="AutoEncoderPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.AutoEncoderPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.BertPLModule" class="md-nav__link">
    BertPLModule
  </a>
  
    <nav class="md-nav" aria-label="BertPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.BertPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.MultimodalTransformerClassificationPLModule" class="md-nav__link">
    MultimodalTransformerClassificationPLModule
  </a>
  
    <nav class="md-nav" aria-label="MultimodalTransformerClassificationPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.MultimodalTransformerClassificationPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.PLModule" class="md-nav__link">
    PLModule
  </a>
  
    <nav class="md-nav" aria-label="PLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.PLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.RnnPLModule" class="md-nav__link">
    RnnPLModule
  </a>
  
    <nav class="md-nav" aria-label="RnnPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.RnnPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule" class="md-nav__link">
    SimplePLModule
  </a>
  
    <nav class="md-nav" aria-label="SimplePLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.aggregate_epoch_metrics" class="md-nav__link">
    aggregate_epoch_metrics()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.configure_optimizers" class="md-nav__link">
    configure_optimizers()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.log_to_console" class="md-nav__link">
    log_to_console()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.test_epoch_end" class="md-nav__link">
    test_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.test_step" class="md-nav__link">
    test_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.training_epoch_end" class="md-nav__link">
    training_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.training_step" class="md-nav__link">
    training_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.validation_epoch_end" class="md-nav__link">
    validation_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.validation_step" class="md-nav__link">
    validation_step()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerClassificationPLModule" class="md-nav__link">
    TransformerClassificationPLModule
  </a>
  
    <nav class="md-nav" aria-label="TransformerClassificationPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerClassificationPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerPLModule" class="md-nav__link">
    TransformerPLModule
  </a>
  
    <nav class="md-nav" aria-label="TransformerPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer" class="md-nav__link">
    slp.plbind.trainer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.add_optimizer_args" class="md-nav__link">
    add_optimizer_args()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.add_trainer_args" class="md-nav__link">
    add_trainer_args()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.make_trainer" class="md-nav__link">
    make_trainer()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.make_trainer_for_ray_tune" class="md-nav__link">
    make_trainer_for_ray_tune()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.watch_model" class="md-nav__link">
    watch_model()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../modules/" class="md-nav__link">
        Generic Modules
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../multimodal/" class="md-nav__link">
        Multimodal Modules
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../utils/" class="md-nav__link">
        SLP utility functions
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../apiref/" class="md-nav__link">
        API reference
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm" class="md-nav__link">
    slp.plbind.dm
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus" class="md-nav__link">
    PLDataModuleFromCorpus
  </a>
  
    <nav class="md-nav" aria-label="PLDataModuleFromCorpus">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.embeddings" class="md-nav__link">
    embeddings
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.vocab_size" class="md-nav__link">
    vocab_size
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromCorpus.add_argparse_args" class="md-nav__link">
    add_argparse_args()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets" class="md-nav__link">
    PLDataModuleFromDatasets
  </a>
  
    <nav class="md-nav" aria-label="PLDataModuleFromDatasets">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.add_argparse_args" class="md-nav__link">
    add_argparse_args()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.prepare_data" class="md-nav__link">
    prepare_data()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.test_dataloader" class="md-nav__link">
    test_dataloader()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.train_dataloader" class="md-nav__link">
    train_dataloader()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.dm.PLDataModuleFromDatasets.val_dataloader" class="md-nav__link">
    val_dataloader()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.dm.split_data" class="md-nav__link">
    split_data()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers" class="md-nav__link">
    slp.plbind.helpers
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger" class="md-nav__link">
    FixedWandbLogger
  </a>
  
    <nav class="md-nav" aria-label="FixedWandbLogger">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FixedWandbLogger.finalize" class="md-nav__link">
    finalize()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits" class="md-nav__link">
    FromLogits
  </a>
  
    <nav class="md-nav" aria-label="FromLogits">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.compute" class="md-nav__link">
    compute()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.helpers.FromLogits.update" class="md-nav__link">
    update()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module" class="md-nav__link">
    slp.plbind.module
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.AutoEncoderPLModule" class="md-nav__link">
    AutoEncoderPLModule
  </a>
  
    <nav class="md-nav" aria-label="AutoEncoderPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.AutoEncoderPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.BertPLModule" class="md-nav__link">
    BertPLModule
  </a>
  
    <nav class="md-nav" aria-label="BertPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.BertPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.MultimodalTransformerClassificationPLModule" class="md-nav__link">
    MultimodalTransformerClassificationPLModule
  </a>
  
    <nav class="md-nav" aria-label="MultimodalTransformerClassificationPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.MultimodalTransformerClassificationPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.PLModule" class="md-nav__link">
    PLModule
  </a>
  
    <nav class="md-nav" aria-label="PLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.PLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.RnnPLModule" class="md-nav__link">
    RnnPLModule
  </a>
  
    <nav class="md-nav" aria-label="RnnPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.RnnPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule" class="md-nav__link">
    SimplePLModule
  </a>
  
    <nav class="md-nav" aria-label="SimplePLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.aggregate_epoch_metrics" class="md-nav__link">
    aggregate_epoch_metrics()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.configure_optimizers" class="md-nav__link">
    configure_optimizers()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.forward" class="md-nav__link">
    forward()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.log_to_console" class="md-nav__link">
    log_to_console()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.test_epoch_end" class="md-nav__link">
    test_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.test_step" class="md-nav__link">
    test_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.training_epoch_end" class="md-nav__link">
    training_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.training_step" class="md-nav__link">
    training_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.validation_epoch_end" class="md-nav__link">
    validation_epoch_end()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.SimplePLModule.validation_step" class="md-nav__link">
    validation_step()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerClassificationPLModule" class="md-nav__link">
    TransformerClassificationPLModule
  </a>
  
    <nav class="md-nav" aria-label="TransformerClassificationPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerClassificationPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerPLModule" class="md-nav__link">
    TransformerPLModule
  </a>
  
    <nav class="md-nav" aria-label="TransformerPLModule">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#slp.plbind.module.TransformerPLModule.__init__" class="md-nav__link">
    __init__()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer" class="md-nav__link">
    slp.plbind.trainer
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.add_optimizer_args" class="md-nav__link">
    add_optimizer_args()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.add_trainer_args" class="md-nav__link">
    add_trainer_args()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.make_trainer" class="md-nav__link">
    make_trainer()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.make_trainer_for_ray_tune" class="md-nav__link">
    make_trainer_for_ray_tune()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#slp.plbind.trainer.watch_model" class="md-nav__link">
    watch_model()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
                
                <h1 id="pytorch-lightning-bindings">Pytorch Lightning Bindings</h1>
<p>These bindings help to build multi-purpose LightningModules and LightningDataModules, that can be utilized for many tasks / datasets.</p>
<p>Note, this is not in line with the pytorch-lightning mantra where everything about an experiment should be contained in a single module.</p>
<p>I agree this can help reproducibility, but I find it tedious to always copy and paste or even worse rewrite boilerplate code for metric calculation and implementing hooks.</p>
<p>With the extensive logging and sane configuration management in slp, reproducibility while developing new models is less of an issue.</p>
<p>My current workflow is to use these modules for fast development cycles, and when I need to publish a specific model, I can then copy and paste it into an isolated LightningModule to make it easier for the future reader. This way we can have the best of both worlds</p>


  <div class="doc doc-object doc-module">

<a id="slp.plbind.dm"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.dm.PLDataModuleFromCorpus" class="doc doc-heading">
        <code>PLDataModuleFromCorpus</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">







  <div class="doc doc-object doc-attribute">



<h3 id="slp.plbind.dm.PLDataModuleFromCorpus.embeddings" class="doc doc-heading">
<code class="highlight language-python"><span class="n">embeddings</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">numpy</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Embeddings matrix</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Optional[numpy.ndarray]</code></td>
      <td><p>Optional[np.ndarray]: Embeddings matrix</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>



  <div class="doc doc-object doc-attribute">



<h3 id="slp.plbind.dm.PLDataModuleFromCorpus.vocab_size" class="doc doc-heading">
<code class="highlight language-python"><span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-property"><code>property</code></small>
      <small class="doc doc-property doc-property-readonly"><code>readonly</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Number of tokens in the vocabulary</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>int</code></td>
      <td><p>int: Number of tokens in the vocabulary</p></td>
    </tr>
  </tbody>
</table>    </div>

  </div>






  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromCorpus.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">train_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_labels</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val_percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">test_percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">batch_size_eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shuffle_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">language_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="s1">&#39;spacy&#39;</span><span class="p">,</span> <span class="n">no_test_set</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">corpus_args</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Wrap raw corpus in a LightningDataModule</p>
<ul>
<li>This handles the selection of the appropriate corpus class based on the tokenizer argument.</li>
<li>If language_model=True it uses the appropriate dataset from slp.data.datasets.</li>
<li>Uses the PLDataModuleFromDatasets to split the val and test sets if not provided</li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>train</code></td>
        <td><code>List</code></td>
        <td><p>Raw train corpus</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>train_labels</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>Train labels. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>val</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>Raw validation corpus. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>val_labels</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>Validation labels. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>test</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>Raw test corpus. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>test_labels</code></td>
        <td><code>Optional[List]</code></td>
        <td><p>Test labels. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>val_percent</code></td>
        <td><code>float</code></td>
        <td><p>Percent of train to be used for validation if no validation set is given. Defaults to 0.2.</p></td>
        <td><code>0.2</code></td>
      </tr>
      <tr>
        <td><code>test_percent</code></td>
        <td><code>float</code></td>
        <td><p>Percent of train to be used for test set if no test set is given. Defaults to 0.2.</p></td>
        <td><code>0.2</code></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>Training batch size. Defaults to 1.</p></td>
        <td><code>64</code></td>
      </tr>
      <tr>
        <td><code>batch_size_eval</code></td>
        <td><code>int</code></td>
        <td><p>Validation and test batch size. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>seed</code></td>
        <td><code>int</code></td>
        <td><p>Seed for deterministic run. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_workers</code></td>
        <td><code>int</code></td>
        <td><p>Number of workers in the DataLoader. Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>pin_memory</code></td>
        <td><code>bool</code></td>
        <td><p>Pin tensors to GPU memory. Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>drop_last</code></td>
        <td><code>bool</code></td>
        <td><p>Drop last incomplete batch. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>sampler_train</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for train loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>sampler_val</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for validation loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>sampler_test</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for test loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_train</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for train loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_val</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for validation loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_test</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for test loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>shuffle_eval</code></td>
        <td><code>bool</code></td>
        <td><p>Shuffle validation and test dataloaders. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>collate_fn</code></td>
        <td><code>Optional[Callable[..., Any]]</code></td>
        <td><p>Collator function. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>language_model</code></td>
        <td><code>bool</code></td>
        <td><p>Use corpus for Language Modeling. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>tokenizer</code></td>
        <td><code>str</code></td>
        <td><p>Select one of the cls.accepted_tokenizers. Defaults to "spacy".</p></td>
        <td><code>&#39;spacy&#39;</code></td>
      </tr>
      <tr>
        <td><code>no_test_set</code></td>
        <td><code>bool</code></td>
        <td><p>Do not create test set. Useful for tuning</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>**corpus_args</code></td>
        <td><code>kwargs</code></td>
        <td><p>Extra arguments to be passed to the corpus. See
slp/data/corpus.py</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>[description]</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>[description]</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="n">List</span><span class="p">,</span>
    <span class="n">train_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">test_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">64</span><span class="p">,</span>
    <span class="n">batch_size_eval</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">shuffle_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sampler_train</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler_val</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler_test</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_train</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_val</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_test</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">language_model</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;spacy&quot;</span><span class="p">,</span>
    <span class="n">no_test_set</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">corpus_args</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrap raw corpus in a LightningDataModule</span>

<span class="sd">    * This handles the selection of the appropriate corpus class based on the tokenizer argument.</span>
<span class="sd">    * If language_model=True it uses the appropriate dataset from slp.data.datasets.</span>
<span class="sd">    * Uses the PLDataModuleFromDatasets to split the val and test sets if not provided</span>

<span class="sd">    Args:</span>
<span class="sd">        train (List): Raw train corpus</span>
<span class="sd">        train_labels (Optional[List]): Train labels. Defaults to None.</span>
<span class="sd">        val (Optional[List]): Raw validation corpus. Defaults to None.</span>
<span class="sd">        val_labels (Optional[List]): Validation labels. Defaults to None.</span>
<span class="sd">        test (Optional[List]): Raw test corpus. Defaults to None.</span>
<span class="sd">        test_labels (Optional[List]): Test labels. Defaults to None.</span>
<span class="sd">        val_percent (float): Percent of train to be used for validation if no validation set is given. Defaults to 0.2.</span>
<span class="sd">        test_percent (float): Percent of train to be used for test set if no test set is given. Defaults to 0.2.</span>
<span class="sd">        batch_size (int): Training batch size. Defaults to 1.</span>
<span class="sd">        batch_size_eval (Optional[int]): Validation and test batch size. Defaults to None.</span>
<span class="sd">        seed (Optional[int]): Seed for deterministic run. Defaults to None.</span>
<span class="sd">        num_workers (int): Number of workers in the DataLoader. Defaults to 1.</span>
<span class="sd">        pin_memory (bool): Pin tensors to GPU memory. Defaults to True.</span>
<span class="sd">        drop_last (bool): Drop last incomplete batch. Defaults to False.</span>
<span class="sd">        sampler_train (Sampler): Sampler for train loader. Defaults to None.</span>
<span class="sd">        sampler_val (Sampler): Sampler for validation loader. Defaults to None.</span>
<span class="sd">        sampler_test (Sampler): Sampler for test loader. Defaults to None.</span>
<span class="sd">        batch_sampler_train (BatchSampler): Batch sampler for train loader. Defaults to None.</span>
<span class="sd">        batch_sampler_val (BatchSampler): Batch sampler for validation loader. Defaults to None.</span>
<span class="sd">        batch_sampler_test (BatchSampler): Batch sampler for test loader. Defaults to None.</span>
<span class="sd">        shuffle_eval (bool): Shuffle validation and test dataloaders. Defaults to False.</span>
<span class="sd">        collate_fn (Callable[..., Any]): Collator function. Defaults to None.</span>
<span class="sd">        language_model (bool): Use corpus for Language Modeling. Defaults to False.</span>
<span class="sd">        tokenizer (str): Select one of the cls.accepted_tokenizers. Defaults to &quot;spacy&quot;.</span>
<span class="sd">        no_test_set (bool): Do not create test set. Useful for tuning</span>
<span class="sd">        **corpus_args (kwargs): Extra arguments to be passed to the corpus. See</span>
<span class="sd">            slp/data/corpus.py</span>
<span class="sd">    Raises:</span>
<span class="sd">        ValueError: [description]</span>
<span class="sd">        ValueError: [description]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">language_model</span> <span class="o">=</span> <span class="n">language_model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tokenizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">corpus_args</span> <span class="o">=</span> <span class="n">corpus_args</span>

    <span class="n">train_data</span><span class="p">,</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_zip_corpus_and_labels</span><span class="p">(</span>
        <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">test</span><span class="p">,</span> <span class="n">train_labels</span><span class="p">,</span> <span class="n">val_labels</span><span class="p">,</span> <span class="n">test_labels</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">no_test_set</span> <span class="o">=</span> <span class="n">no_test_set</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PLDataModuleFromCorpus</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">train_data</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">val</span><span class="o">=</span><span class="n">val_data</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">test</span><span class="o">=</span><span class="n">test_data</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
        <span class="n">val_percent</span><span class="o">=</span><span class="n">val_percent</span><span class="p">,</span>
        <span class="n">test_percent</span><span class="o">=</span><span class="n">test_percent</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">batch_size_eval</span><span class="o">=</span><span class="n">batch_size_eval</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="n">drop_last</span><span class="p">,</span>
        <span class="n">shuffle_eval</span><span class="o">=</span><span class="n">shuffle_eval</span><span class="p">,</span>
        <span class="n">sampler_train</span><span class="o">=</span><span class="n">sampler_train</span><span class="p">,</span>
        <span class="n">sampler_val</span><span class="o">=</span><span class="n">sampler_val</span><span class="p">,</span>
        <span class="n">sampler_test</span><span class="o">=</span><span class="n">sampler_test</span><span class="p">,</span>
        <span class="n">batch_sampler_train</span><span class="o">=</span><span class="n">batch_sampler_train</span><span class="p">,</span>
        <span class="n">batch_sampler_val</span><span class="o">=</span><span class="n">batch_sampler_val</span><span class="p">,</span>
        <span class="n">batch_sampler_test</span><span class="o">=</span><span class="n">batch_sampler_test</span><span class="p">,</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="n">collate_fn</span><span class="p">,</span>
        <span class="n">no_test_set</span><span class="o">=</span><span class="n">no_test_set</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromCorpus.add_argparse_args" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_argparse_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Augment input parser with arguments for data loading and corpus processing</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parent_parser</code></td>
        <td><code>argparse.ArgumentParser</code></td>
        <td><p>Parser created by the user</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>argparse.ArgumentParser</code></td>
      <td><p>Augmented parser</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">parent_parser</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Augment input parser with arguments for data loading and corpus processing</span>

<span class="sd">    Args:</span>
<span class="sd">        parent_parser (argparse.ArgumentParser): Parser created by the user</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.ArgumentParser: Augmented parser</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="nb">super</span><span class="p">(</span><span class="n">PLDataModuleFromCorpus</span><span class="p">,</span> <span class="bp">cls</span><span class="p">)</span><span class="o">.</span><span class="n">add_argparse_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tokenizer&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.tokenizer&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="o">.</span><span class="n">lower</span><span class="p">,</span>
        <span class="c1"># Corpus can already be tokenized, you can use spacy for word tokenization or any tokenizer from hugging face</span>
        <span class="n">choices</span><span class="o">=</span><span class="bp">cls</span><span class="o">.</span><span class="n">accepted_tokenizers</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;spacy&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Token type. The tokenization will happen at this level.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Only when tokenizer == spacy</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--limit-vocab&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.limit_vocab_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Limit vocab size. -1 means use the whole vocab. Applicable only when --tokenizer=spacy&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--embeddings-file&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.embeddings_file&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="n">dir_path</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to file with pretrained embeddings. Applicable only when --tokenizer=spacy&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--embeddings-dim&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.embeddings_dim&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Embedding dim of pretrained embeddings. Applicable only when --tokenizer=spacy&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lang&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.lang&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;en_core_web_md&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Language for spacy tokenizer, e.g. en_core_web_md. Applicable only when --tokenizer=spacy&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-add-specials&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.add_special_tokens&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Do not add special tokens for hugging face tokenizers&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Generic args</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lower&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.lower&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Convert to lowercase.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--prepend-bos&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.prepend_bos&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Prepend [BOS] token&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--append-eos&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.append_eos&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Append [EOS] token&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--max-sentence-length&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.max_len&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum allowed sentence length. -1 means use the whole sentence&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.dm.PLDataModuleFromDatasets" class="doc doc-heading">
        <code>PLDataModuleFromDatasets</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train</span><span class="p">,</span> <span class="n">val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">val_percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">test_percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size_eval</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">sampler_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">sampler_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_train</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_val</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">batch_sampler_test</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">shuffle_eval</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">collate_fn</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">no_test_set</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>LightningDataModule wrapper for generic torch.utils.data.Dataset</p>
<p>If val or test Datasets are not provided, this class will split
val_pecent and test_percent of the train set respectively to create them</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>train</code></td>
        <td><code>Dataset</code></td>
        <td><p>Train set</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>val</code></td>
        <td><code>Dataset</code></td>
        <td><p>Validation set. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>test</code></td>
        <td><code>Dataset</code></td>
        <td><p>Test set. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>val_percent</code></td>
        <td><code>float</code></td>
        <td><p>Percent of train to be used for validation if no validation set is given. Defaults to 0.2.</p></td>
        <td><code>0.2</code></td>
      </tr>
      <tr>
        <td><code>test_percent</code></td>
        <td><code>float</code></td>
        <td><p>Percent of train to be used for test set if no test set is given. Defaults to 0.2.</p></td>
        <td><code>0.2</code></td>
      </tr>
      <tr>
        <td><code>batch_size</code></td>
        <td><code>int</code></td>
        <td><p>Training batch size. Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>batch_size_eval</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Validation and test batch size. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>seed</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Seed for deterministic run. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>num_workers</code></td>
        <td><code>int</code></td>
        <td><p>Number of workers in the DataLoader. Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>pin_memory</code></td>
        <td><code>bool</code></td>
        <td><p>Pin tensors to GPU memory. Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>drop_last</code></td>
        <td><code>bool</code></td>
        <td><p>Drop last incomplete batch. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>sampler_train</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for train loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>sampler_val</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for validation loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>sampler_test</code></td>
        <td><code>Sampler</code></td>
        <td><p>Sampler for test loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_train</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for train loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_val</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for validation loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>batch_sampler_test</code></td>
        <td><code>BatchSampler</code></td>
        <td><p>Batch sampler for test loader. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>shuffle_eval</code></td>
        <td><code>bool</code></td>
        <td><p>Shuffle validation and test dataloaders. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>collate_fn</code></td>
        <td><code>Optional[Callable[..., Any]]</code></td>
        <td><p>Collator function. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>no_test_set</code></td>
        <td><code>bool</code></td>
        <td><p>Do not create test set. Useful for tuning</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Exceptions:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both mutually exclusive sampler_train and batch_sampler_train are provided</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both mutually exclusive sampler_val and batch_sampler_val are provided</p></td>
      </tr>
      <tr>
        <td><code>ValueError</code></td>
        <td><p>If both mutually exclusive sampler_test and batch_sampler_test are provided</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">train</span><span class="p">:</span> <span class="n">Dataset</span><span class="p">,</span>
    <span class="n">val</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test</span><span class="p">:</span> <span class="n">Dataset</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">val_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">test_percent</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">batch_size_eval</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">pin_memory</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">drop_last</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">sampler_train</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler_val</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampler_test</span><span class="p">:</span> <span class="n">Sampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_train</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_val</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">batch_sampler_test</span><span class="p">:</span> <span class="n">BatchSampler</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">shuffle_eval</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">collate_fn</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">no_test_set</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;LightningDataModule wrapper for generic torch.utils.data.Dataset</span>

<span class="sd">    If val or test Datasets are not provided, this class will split</span>
<span class="sd">    val_pecent and test_percent of the train set respectively to create them</span>

<span class="sd">    Args:</span>
<span class="sd">        train (Dataset): Train set</span>
<span class="sd">        val (Dataset): Validation set. Defaults to None.</span>
<span class="sd">        test (Dataset): Test set. Defaults to None.</span>
<span class="sd">        val_percent (float): Percent of train to be used for validation if no validation set is given. Defaults to 0.2.</span>
<span class="sd">        test_percent (float): Percent of train to be used for test set if no test set is given. Defaults to 0.2.</span>
<span class="sd">        batch_size (int): Training batch size. Defaults to 1.</span>
<span class="sd">        batch_size_eval (Optional[int]): Validation and test batch size. Defaults to None.</span>
<span class="sd">        seed (Optional[int]): Seed for deterministic run. Defaults to None.</span>
<span class="sd">        num_workers (int): Number of workers in the DataLoader. Defaults to 1.</span>
<span class="sd">        pin_memory (bool): Pin tensors to GPU memory. Defaults to True.</span>
<span class="sd">        drop_last (bool): Drop last incomplete batch. Defaults to False.</span>
<span class="sd">        sampler_train (Sampler): Sampler for train loader. Defaults to None.</span>
<span class="sd">        sampler_val (Sampler): Sampler for validation loader. Defaults to None.</span>
<span class="sd">        sampler_test (Sampler): Sampler for test loader. Defaults to None.</span>
<span class="sd">        batch_sampler_train (BatchSampler): Batch sampler for train loader. Defaults to None.</span>
<span class="sd">        batch_sampler_val (BatchSampler): Batch sampler for validation loader. Defaults to None.</span>
<span class="sd">        batch_sampler_test (BatchSampler): Batch sampler for test loader. Defaults to None.</span>
<span class="sd">        shuffle_eval (bool): Shuffle validation and test dataloaders. Defaults to False.</span>
<span class="sd">        collate_fn (Callable[..., Any]): Collator function. Defaults to None.</span>
<span class="sd">        no_test_set (bool): Do not create test set. Useful for tuning</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: If both mutually exclusive sampler_train and batch_sampler_train are provided</span>
<span class="sd">        ValueError: If both mutually exclusive sampler_val and batch_sampler_val are provided</span>
<span class="sd">        ValueError: If both mutually exclusive sampler_test and batch_sampler_test are provided</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PLDataModuleFromDatasets</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">setup_has_run</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="n">batch_sampler_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sampler_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You provided both a sampler and a batch sampler for the train set. These are mutually exclusive&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">batch_sampler_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sampler_val</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You provided both a sampler and a batch sampler for the validation set. These are mutually exclusive&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">batch_sampler_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">sampler_test</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;You provided both a sampler and a batch sampler for the test set. These are mutually exclusive&quot;</span>
        <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">val_percent</span> <span class="o">=</span> <span class="n">val_percent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test_percent</span> <span class="o">=</span> <span class="n">test_percent</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sampler_train</span> <span class="o">=</span> <span class="n">sampler_train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sampler_val</span> <span class="o">=</span> <span class="n">sampler_val</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">sampler_test</span> <span class="o">=</span> <span class="n">sampler_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_train</span> <span class="o">=</span> <span class="n">batch_sampler_train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_val</span> <span class="o">=</span> <span class="n">batch_sampler_val</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_test</span> <span class="o">=</span> <span class="n">batch_sampler_test</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span> <span class="o">=</span> <span class="n">num_workers</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span> <span class="o">=</span> <span class="n">pin_memory</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="o">=</span> <span class="n">drop_last</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_eval</span> <span class="o">=</span> <span class="n">shuffle_eval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span> <span class="o">=</span> <span class="n">collate_fn</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>

    <span class="k">if</span> <span class="n">batch_size_eval</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">batch_size_eval</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">no_test_set</span> <span class="o">=</span> <span class="n">no_test_set</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">batch_size_eval</span> <span class="o">=</span> <span class="n">batch_size_eval</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">train</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">val</span> <span class="o">=</span> <span class="n">val</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">test</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.add_argparse_args" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_argparse_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-classmethod"><code>classmethod</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Augment input parser with arguments for data loading</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parent_parser</code></td>
        <td><code>ArgumentParser</code></td>
        <td><p>Parser created by the user</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ArgumentParser</code></td>
      <td><p>argparse.ArgumentParser: Augmented parser</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span> <span class="nf">add_argparse_args</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span> <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Augment input parser with arguments for data loading</span>

<span class="sd">    Args:</span>
<span class="sd">        parent_parser (argparse.ArgumentParser): Parser created by the user</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.ArgumentParser: Augmented parser</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">parent_parser</span><span class="p">],</span> <span class="n">add_help</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--val-percent&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.val_percent&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Percent of validation data to be randomly split from the training set, if no validation set is provided&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--test-percent&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.test_percent&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Percent of test data to be randomly split from the training set, if no test set is provided&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--bsz&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.batch_size&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Training batch size&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--bsz-eval&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.batch_size_eval&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Evaluation batch size&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-workers&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.num_workers&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of workers to be used in the DataLoader&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-pin-memory&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.pin_memory&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Don&#39;t pin data to GPU memory when transferring&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--drop-last&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.drop_last&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Drop last incomplete batch&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--no-shuffle-eval&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;data.shuffle_eval&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_false&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Don&#39;t shuffle val &amp; test sets&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.prepare_data" class="doc doc-heading">
<code class="highlight language-python"><span class="n">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Use this to download and prepare data.</p>
<p>.. warning:: DO NOT set state to the model (use <code>setup</code> instead)
    since this is NOT called on every GPU in DDP/TPU</p>
<p>Example::</p>
<pre><code>def prepare_data(self):
    # good
    download_data()
    tokenize()
    etc()

    # bad
    self.split = data_split
    self.some_state = some_other_state()
</code></pre>
<p>In DDP prepare_data can be called in two ways (using Trainer(prepare_data_per_node)):</p>
<ol>
<li>Once per node. This is the default and is only called on LOCAL_RANK=0.</li>
<li>Once in total. Only called on GLOBAL_RANK=0.</li>
</ol>
<p>Example::</p>
<pre><code># DEFAULT
# called once per node on LOCAL_RANK=0 of that node
Trainer(prepare_data_per_node=True)

# call on GLOBAL_RANK=0 (great for shared file systems)
Trainer(prepare_data_per_node=False)
</code></pre>
<p>This is called before requesting the dataloaders:</p>
<p>.. code-block:: python</p>
<pre><code>model.prepare_data()
    if ddp/tpu: init()
model.setup(stage)
model.train_dataloader()
model.val_dataloader()
model.test_dataloader()
</code></pre>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="kc">None</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.test_dataloader" class="doc doc-heading">
<code class="highlight language-python"><span class="n">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Configure test DataLoader</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataLoader</code></td>
      <td><p>Pytorch DataLoader for test set</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configure test DataLoader</span>

<span class="sd">    Returns:</span>
<span class="sd">        DataLoader: Pytorch DataLoader for test set</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size_eval</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_test</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_test</span><span class="p">,</span>
        <span class="n">batch_sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_test</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_eval</span>
            <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_test</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.train_dataloader" class="doc doc-heading">
<code class="highlight language-python"><span class="n">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Configure train DataLoader</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataLoader</code></td>
      <td><p>DataLoader: Pytorch DataLoader for train set</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configure train DataLoader</span>

<span class="sd">    Returns:</span>
<span class="sd">        DataLoader: Pytorch DataLoader for train set</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_train</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_train</span><span class="p">,</span>
        <span class="n">batch_sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_train</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.dm.PLDataModuleFromDatasets.val_dataloader" class="doc doc-heading">
<code class="highlight language-python"><span class="n">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Configure validation DataLoader</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataLoader</code></td>
      <td><p>Pytorch DataLoader for validation set</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Configure validation DataLoader</span>

<span class="sd">    Returns:</span>
<span class="sd">        DataLoader: Pytorch DataLoader for validation set</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">val</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size_eval</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_val</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_workers</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">pin_memory</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">,</span>
        <span class="n">drop_last</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">drop_last</span> <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">),</span>
        <span class="n">sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_val</span><span class="p">,</span>
        <span class="n">batch_sampler</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_val</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">shuffle_eval</span>
            <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_sampler_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
            <span class="ow">and</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sampler_val</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="p">),</span>
        <span class="n">collate_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">collate_fn</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">val</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>




  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.dm.split_data" class="doc doc-heading">
<code class="highlight language-python"><span class="n">split_data</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Train-test split of dataset.</p>
<p>Dataset can be either a torch.utils.data.Dataset or a list</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>dataset</code></td>
        <td><code>Union[Dataset, List]</code></td>
        <td><p>Input dataset</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>test_size</code></td>
        <td><code>float</code></td>
        <td><p>Size of the test set. Defaults to 0.2.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>seed</code></td>
        <td><code>int</code></td>
        <td><p>Optional seed for deterministic run. Defaults to None.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[Union[Dataset, List], Union[Dataset, List]</code></td>
      <td><p>(train set, test set)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/dm.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">split_data</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">test_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Train-test split of dataset.</span>

<span class="sd">    Dataset can be either a torch.utils.data.Dataset or a list</span>

<span class="sd">    Args:</span>
<span class="sd">        dataset (Union[Dataset, List]): Input dataset</span>
<span class="sd">        test_size (float): Size of the test set. Defaults to 0.2.</span>
<span class="sd">        seed (int): Optional seed for deterministic run. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Union[Dataset, List], Union[Dataset, List]: (train set, test set)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="p">):</span>
        <span class="n">test_len</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">test_size</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>
        <span class="n">train_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">-</span> <span class="n">test_len</span>

        <span class="n">seed_generator</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">seed_generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">random_split</span><span class="p">(</span>
            <span class="n">dataset</span><span class="p">,</span> <span class="p">[</span><span class="n">train_len</span><span class="p">,</span> <span class="n">test_len</span><span class="p">],</span> <span class="n">generator</span><span class="o">=</span><span class="n">seed_generator</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>

        <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">

<a id="slp.plbind.helpers"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">








  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.helpers.FixedWandbLogger" class="doc doc-heading">
        <code>FixedWandbLogger</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.helpers.FixedWandbLogger.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">offline</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="nb">id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">anonymous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">log_model</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prefix</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">sync_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">checkpoint_dir</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Wandb logger fix to save checkpoints in wandb</p>
<p>Accepts an additional checkpoint_dir argument, pointing to the real checkpoint directory</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>name</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Display name for the run. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>save_dir</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Path where data is saved. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>offline</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Run offline (data can be streamed later to wandb servers). Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>id</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Sets the version, mainly used to resume a previous run. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>anonymous</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Enables or explicitly disables anonymous logging. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>version</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Sets the version, mainly used to resume a previous run. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>project</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>The name of the project to which this run will belong. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>log_model</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Save checkpoints in wandb dir to upload on W&amp;B servers. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>experiment</code></td>
        <td><code>Run</code></td>
        <td><p>WandB experiment object. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>prefix</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>A string to put at the beginning of metric keys. Defaults to "".</p></td>
        <td><code>&#39;&#39;</code></td>
      </tr>
      <tr>
        <td><code>sync_step</code></td>
        <td><code>Optional[bool]</code></td>
        <td><p>Sync Trainer step with wandb step. Defaults to True.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>checkpoint_dir</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Real checkpoint dir. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/helpers.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">save_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">offline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="nb">id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">anonymous</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">version</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">log_model</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">experiment</span><span class="p">:</span> <span class="n">wandb</span><span class="o">.</span><span class="n">sdk</span><span class="o">.</span><span class="n">wandb_run</span><span class="o">.</span><span class="n">Run</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prefix</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
    <span class="n">sync_step</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">checkpoint_dir</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wandb logger fix to save checkpoints in wandb</span>

<span class="sd">    Accepts an additional checkpoint_dir argument, pointing to the real checkpoint directory</span>

<span class="sd">    Args:</span>
<span class="sd">        name (Optional[str]): Display name for the run. Defaults to None.</span>
<span class="sd">        save_dir (Optional[str]): Path where data is saved. Defaults to None.</span>
<span class="sd">        offline (Optional[bool]): Run offline (data can be streamed later to wandb servers). Defaults to False.</span>
<span class="sd">        id (Optional[str]): Sets the version, mainly used to resume a previous run. Defaults to None.</span>
<span class="sd">        anonymous (Optional[bool]): Enables or explicitly disables anonymous logging. Defaults to False.</span>
<span class="sd">        version (Optional[str]): Sets the version, mainly used to resume a previous run. Defaults to None.</span>
<span class="sd">        project (Optional[str]): The name of the project to which this run will belong. Defaults to None.</span>
<span class="sd">        log_model (Optional[bool]): Save checkpoints in wandb dir to upload on W&amp;B servers. Defaults to False.</span>
<span class="sd">        experiment ([type]): WandB experiment object. Defaults to None.</span>
<span class="sd">        prefix (Optional[str]): A string to put at the beginning of metric keys. Defaults to &quot;&quot;.</span>
<span class="sd">        sync_step (Optional[bool]): Sync Trainer step with wandb step. Defaults to True.</span>
<span class="sd">        checkpoint_dir (Optional[str]): Real checkpoint dir. Defaults to None.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_dir</span> <span class="o">=</span> <span class="n">checkpoint_dir</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FixedWandbLogger</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
        <span class="n">save_dir</span><span class="o">=</span><span class="n">save_dir</span><span class="p">,</span>
        <span class="n">offline</span><span class="o">=</span><span class="n">offline</span><span class="p">,</span>
        <span class="nb">id</span><span class="o">=</span><span class="nb">id</span><span class="p">,</span>
        <span class="n">anonymous</span><span class="o">=</span><span class="n">anonymous</span><span class="p">,</span>
        <span class="n">version</span><span class="o">=</span><span class="n">version</span><span class="p">,</span>
        <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span>
        <span class="n">log_model</span><span class="o">=</span><span class="n">log_model</span><span class="p">,</span>
        <span class="n">experiment</span><span class="o">=</span><span class="n">experiment</span><span class="p">,</span>
        <span class="n">prefix</span><span class="o">=</span><span class="n">prefix</span><span class="p">,</span>
        <span class="n">sync_step</span><span class="o">=</span><span class="n">sync_step</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.helpers.FixedWandbLogger.finalize" class="doc doc-heading">
<code class="highlight language-python"><span class="n">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">status</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Determine where checkpoints are saved and upload to wandb servers</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>status</code></td>
        <td><code>str</code></td>
        <td><p>Experiment status</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/helpers.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="nd">@rank_zero_only</span>
<span class="k">def</span> <span class="nf">finalize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">status</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Determine where checkpoints are saved and upload to wandb servers</span>

<span class="sd">    Args:</span>
<span class="sd">        status (str): Experiment status</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># offset future training logged on same W&amp;B run</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experiment</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_step_offset</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_experiment</span><span class="o">.</span><span class="n">step</span>

    <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_dir</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_checkpoint_dir</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">save_dir</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">checkpoint_dir</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Invalid checkpoint dir. Checkpoints will not be uploaded to Wandb.&quot;</span>
        <span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;You can manually upload your checkpoints through the CLI interface.&quot;</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># upload all checkpoints from saving dir</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_log_model</span><span class="p">:</span>
            <span class="n">wandb</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint_dir</span><span class="p">,</span> <span class="s2">&quot;*.ckpt&quot;</span><span class="p">))</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.helpers.FromLogits" class="doc doc-heading">
        <code>FromLogits</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.helpers.FromLogits.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Wrap pytorch lighting metric to accept logits input</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>metric</code></td>
        <td><code>Metric</code></td>
        <td><p>The metric to wrap, e.g. pl.metrics.Accuracy</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/helpers.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrap pytorch lighting metric to accept logits input</span>

<span class="sd">    Args:</span>
<span class="sd">        metric (pl.metrics.Metric): The metric to wrap, e.g. pl.metrics.Accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FromLogits</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">compute_on_step</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">compute_on_step</span><span class="p">,</span>
        <span class="n">dist_sync_on_step</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">dist_sync_on_step</span><span class="p">,</span>
        <span class="n">process_group</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">process_group</span><span class="p">,</span>
        <span class="n">dist_sync_fn</span><span class="o">=</span><span class="n">metric</span><span class="o">.</span><span class="n">dist_sync_fn</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric</span> <span class="o">=</span> <span class="n">metric</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.helpers.FromLogits.compute" class="doc doc-heading">
<code class="highlight language-python"><span class="n">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Compute metric</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tensor</code></td>
      <td><p>torch.Tensor: metric value</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/helpers.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Compute metric</span>

<span class="sd">    Returns:</span>
<span class="sd">        torch.Tensor: metric value</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">()</span>  <span class="c1"># type: ignore</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.helpers.FromLogits.update" class="doc doc-heading">
<code class="highlight language-python"><span class="n">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Update underlying metric</p>
<p>Calculate softmax under the hood and pass probs to the underlying metric</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>preds</code></td>
        <td><code>Tensor</code></td>
        <td><p>[B, *, num_classes] Logits</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>target</code></td>
        <td><code>Tensor</code></td>
        <td><p>[B, *] Ground truths</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/helpers.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">preds</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">target</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>  <span class="c1"># type: ignore</span>
    <span class="sd">&quot;&quot;&quot;Update underlying metric</span>

<span class="sd">    Calculate softmax under the hood and pass probs to the underlying metric</span>

<span class="sd">    Args:</span>
<span class="sd">        preds (torch.Tensor): [B, *, num_classes] Logits</span>
<span class="sd">        target (torch.Tensor): [B, *] Ground truths</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">metric</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># type: ignore</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">

<a id="slp.plbind.module"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">







  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.AutoEncoderPLModule" class="doc doc-heading">
        <code>AutoEncoderPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.AutoEncoderPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">AutoEncoderPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_AutoEncoder</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.BertPLModule" class="doc doc-heading">
        <code>BertPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.BertPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BertPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_BertSequenceClassification</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.MultimodalTransformerClassificationPLModule" class="doc doc-heading">
        <code>MultimodalTransformerClassificationPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.MultimodalTransformerClassificationPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">MultimodalTransformerClassificationPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_MultimodalTransformerClassification</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.PLModule" class="doc doc-heading">
        <code>PLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.PLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">PLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_Classification</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.RnnPLModule" class="doc doc-heading">
        <code>RnnPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.RnnPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">RnnPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_RnnClassification</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.SimplePLModule" class="doc doc-heading">
        <code>SimplePLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">predictor_cls</span><span class="o">=&lt;</span><span class="k">class</span> <span class="err">&#39;</span><span class="nc">slp</span><span class="o">.</span><span class="n">plbind</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">_Classification</span><span class="s1">&#39;&gt;, calculate_perplexity=False)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Wraps a (model, optimizer, criterion, lr_scheduler) tuple in a LightningModule</p>
<p>Handles the boilerplate for metrics calculation and logging and defines the train_step / val_step / test_step
with use of the predictor helper classes (e.g. _Classification, _RnnClassification)</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>model</code></td>
        <td><code>Module</code></td>
        <td><p>Module to use for prediction</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>optimizer</code></td>
        <td><code>Union[torch.optim.optimizer.Optimizer, List[torch.optim.optimizer.Optimizer]]</code></td>
        <td><p>Optimizers to use for training</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>criterion</code></td>
        <td><code>Union[torch.nn.modules.module.Module, Callable]</code></td>
        <td><p>Task loss</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>lr_scheduler</code></td>
        <td><code>Union[torch.optim.lr_scheduler._LRScheduler, List[torch.optim.lr_scheduler._LRScheduler]]</code></td>
        <td><p>Learning rate scheduler. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>hparams</code></td>
        <td><code>Union[omegaconf.dictconfig.DictConfig, Dict[str, Any], argparse.Namespace]</code></td>
        <td><p>Hyperparameter values. This ensures they are logged with trainer.loggers. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>metrics</code></td>
        <td><code>Optional[Dict[str, pytorch_lightning.metrics.metric.Metric]]</code></td>
        <td><p>Metrics to track. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>predictor_cls</code></td>
        <td><code>[type]</code></td>
        <td><p>Class that defines a parse_batch and a
    get_predictions_and_targets method. Defaults to _Classification.</p></td>
        <td><code>&lt;class &#39;slp.plbind.module._Classification&#39;&gt;</code></td>
      </tr>
      <tr>
        <td><code>calculate_perplexity</code></td>
        <td><code>bool</code></td>
        <td><p>Whether to calculate perplexity.
    Would be cleaner as a metric, but this is more efficient. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_Classification</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># for LM. Dirty but much more efficient</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wraps a (model, optimizer, criterion, lr_scheduler) tuple in a LightningModule</span>

<span class="sd">    Handles the boilerplate for metrics calculation and logging and defines the train_step / val_step / test_step</span>
<span class="sd">    with use of the predictor helper classes (e.g. _Classification, _RnnClassification)</span>

<span class="sd">    Args:</span>
<span class="sd">        model (nn.Module): Module to use for prediction</span>
<span class="sd">        optimizer (Union[Optimizer, List[Optimizer]]): Optimizers to use for training</span>
<span class="sd">        criterion (LossType): Task loss</span>
<span class="sd">        lr_scheduler (Union[_LRScheduler, List[_LRScheduler]], optional): Learning rate scheduler. Defaults to None.</span>
<span class="sd">        hparams (Configuration, optional): Hyperparameter values. This ensures they are logged with trainer.loggers. Defaults to None.</span>
<span class="sd">        metrics (Optional[Dict[str, pl.metrics.Metric]], optional): Metrics to track. Defaults to None.</span>
<span class="sd">        predictor_cls ([type], optional): Class that defines a parse_batch and a</span>
<span class="sd">                get_predictions_and_targets method. Defaults to _Classification.</span>
<span class="sd">        calculate_perplexity (bool, optional): Whether to calculate perplexity.</span>
<span class="sd">                Would be cleaner as a metric, but this is more efficient. Defaults to False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">SimplePLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">calculate_perplexity</span> <span class="o">=</span> <span class="n">calculate_perplexity</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span> <span class="o">=</span> <span class="n">criterion</span>

    <span class="k">if</span> <span class="n">metrics</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">({</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span>
            <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">(</span><span class="n">modules</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span> <span class="o">=</span> <span class="n">predictor_cls</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">hparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">Namespace</span><span class="p">):</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="nb">vars</span><span class="p">(</span><span class="n">hparams</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">hparams</span><span class="p">,</span> <span class="n">DictConfig</span><span class="p">):</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span> <span class="n">OmegaConf</span><span class="o">.</span><span class="n">to_container</span><span class="p">(</span><span class="n">hparams</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">dict_params</span> <span class="o">=</span> <span class="n">hparams</span>
        <span class="c1"># self.hparams = dict_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">save_hyperparameters</span><span class="p">(</span><span class="n">dict_params</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.aggregate_epoch_metrics" class="doc doc-heading">
<code class="highlight language-python"><span class="n">aggregate_epoch_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Aggregate metrics over a whole epoch</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>outputs</code></td>
        <td><code>List[Dict[str, torch.Tensor]]</code></td>
        <td><p>Aggregated outputs from train_step, validation_step or test_step</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>mode</code></td>
        <td><code>str</code></td>
        <td><p>"Training", "Validation" or "Testing". Defaults to "Training".</p></td>
        <td><code>&#39;Training&#39;</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">aggregate_epoch_metrics</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate metrics over a whole epoch</span>

<span class="sd">    Args:</span>
<span class="sd">        outputs (List[Dict[str, torch.Tensor]]): Aggregated outputs from train_step, validation_step or test_step</span>
<span class="sd">        mode (str, optional): &quot;Training&quot;, &quot;Validation&quot; or &quot;Testing&quot;. Defaults to &quot;Training&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="nf">fmt</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Format metric name&quot;&quot;&quot;</span>

        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">if</span> <span class="n">name</span> <span class="o">!=</span> <span class="s2">&quot;loss&quot;</span> <span class="k">else</span> <span class="s2">&quot;train_loss&quot;</span>

    <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">aggregated</span> <span class="o">=</span> <span class="p">{</span><span class="n">fmt</span><span class="p">(</span><span class="n">k</span><span class="p">):</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">x</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span><span class="p">}</span>
    <span class="n">aggregated</span><span class="p">[</span><span class="s2">&quot;epoch&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span><span class="n">aggregated</span><span class="p">,</span> <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">on_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">aggregated</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.configure_optimizers" class="doc doc-heading">
<code class="highlight language-python"><span class="n">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Return optimizers and learning rate schedulers</p>

<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[List[Optimizer], List[_LRScheduler]]</code></td>
      <td><p>(optimizers, lr_schedulers)</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">configure_optimizers</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Return optimizers and learning rate schedulers</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[List[Optimizer], List[_LRScheduler]]: (optimizers, lr_schedulers)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">scheduler</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;scheduler&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="p">,</span>
            <span class="s2">&quot;interval&quot;</span><span class="p">:</span> <span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
            <span class="s2">&quot;monitor&quot;</span><span class="p">:</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="p">],</span> <span class="p">[</span><span class="n">scheduler</span><span class="p">]</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.forward" class="doc doc-heading">
<code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Call wrapped module forward</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Call wrapped module forward&quot;&quot;&quot;</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.log_to_console" class="doc doc-heading">
<code class="highlight language-python"><span class="n">log_to_console</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Log metrics to console</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>metrics</code></td>
        <td><code>Dict[str, torch.Tensor]</code></td>
        <td><p>Computed metrics</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>mode</code></td>
        <td><code>str</code></td>
        <td><p>"Training", "Validation" or "Testing". Defaults to "Training".</p></td>
        <td><code>&#39;Training&#39;</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">log_to_console</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Log metrics to console</span>

<span class="sd">    Args:</span>
<span class="sd">        metrics (Dict[str, torch.Tensor]): Computed metrics</span>
<span class="sd">        mode (str, optional): &quot;Training&quot;, &quot;Validation&quot; or &quot;Testing&quot;. Defaults to &quot;Training&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">{}</span><span class="s2"> </span><span class="si">{}</span><span class="s2"> results&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">current_epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">mode</span><span class="p">))</span>
    <span class="n">print_separator</span><span class="p">(</span><span class="n">symbol</span><span class="o">=</span><span class="s2">&quot;-&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s2">&quot;epoch&quot;</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{:&lt;15}</span><span class="s2"> </span><span class="si">{:&lt;15}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">value</span><span class="p">))</span>

    <span class="n">print_separator</span><span class="p">(</span><span class="n">symbol</span><span class="o">=</span><span class="s2">&quot;%&quot;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">print_fn</span><span class="o">=</span><span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.test_epoch_end" class="doc doc-heading">
<code class="highlight language-python"><span class="n">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Aggregate metrics of a test epoch</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>outputs</code></td>
        <td><code>List[Dict[str, torch.Tensor]]</code></td>
        <td><p>Aggregated outputs from test_step</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate metrics of a test epoch</span>

<span class="sd">    Args:</span>
<span class="sd">        outputs (List[Dict[str, torch.Tensor]]): Aggregated outputs from test_step</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_epoch_metrics</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_to_console</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Test&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.test_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Compute loss for a single test step and log metrics to loggers</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>Tuple[torch.Tensor, ...]</code></td>
        <td><p>Input batch</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td><code>int</code></td>
        <td><p>Index of batch</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, torch.Tensor]</code></td>
      <td><p>computed metrics</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">test_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute loss for a single test step and log metrics to loggers</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (Tuple[torch.Tensor, ...]): Input batch</span>
<span class="sd">        batch_idx (int): Index of batch</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: computed metrics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="o">.</span><span class="n">get_predictions_and_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test_metrics</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;test&quot;</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.training_epoch_end" class="doc doc-heading">
<code class="highlight language-python"><span class="n">training_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Aggregate metrics of a training epoch</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>outputs</code></td>
        <td><code>List[Dict[str, torch.Tensor]]</code></td>
        <td><p>Aggregated outputs from train_step</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">training_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate metrics of a training epoch</span>

<span class="sd">    Args:</span>
<span class="sd">        outputs (List[Dict[str, torch.Tensor]]): Aggregated outputs from train_step</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_epoch_metrics</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_to_console</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Training&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.training_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Compute loss for a single training step and log metrics to loggers</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>Tuple[torch.Tensor, ...]</code></td>
        <td><p>Input batch</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td><code>int</code></td>
        <td><p>Index of batch</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, torch.Tensor]</code></td>
      <td><p>computed metrics</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute loss for a single training step and log metrics to loggers</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (Tuple[torch.Tensor, ...]): Input batch</span>
<span class="sd">        batch_idx (int): Index of batch</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: computed metrics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="o">.</span><span class="n">get_predictions_and_targets</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_metrics</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span>
    <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">log_dict</span><span class="p">(</span>
        <span class="n">metrics</span><span class="p">,</span>
        <span class="n">on_step</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">on_epoch</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">logger</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">prog_bar</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">metrics</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.validation_epoch_end" class="doc doc-heading">
<code class="highlight language-python"><span class="n">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Aggregate metrics of a validation epoch</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>outputs</code></td>
        <td><code>List[Dict[str, torch.Tensor]]</code></td>
        <td><p>Aggregated outputs from validation_step</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">validation_epoch_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">outputs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Aggregate metrics of a validation epoch</span>

<span class="sd">    Args:</span>
<span class="sd">        outputs (List[Dict[str, torch.Tensor]]): Aggregated outputs from validation_step</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">aggregate_epoch_metrics</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">])</span> <span class="ow">or</span> <span class="n">torch</span><span class="o">.</span><span class="n">isinf</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]):</span>
        <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;val_loss&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1000000</span>

    <span class="n">outputs</span><span class="p">[</span><span class="s2">&quot;best_score&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span>
        <span class="n">outputs</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">early_stopping_callback</span><span class="o">.</span><span class="n">monitor</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">early_stopping_callback</span><span class="o">.</span><span class="n">best_score</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_to_console</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;Validation&quot;</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.SimplePLModule.validation_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span></code>


</h3>

    <div class="doc doc-contents ">

      <p>Compute loss for a single validation step and log metrics to loggers</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>batch</code></td>
        <td><code>Tuple[torch.Tensor, ...]</code></td>
        <td><p>Input batch</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>batch_idx</code></td>
        <td><code>int</code></td>
        <td><p>Index of batch</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Dict[str, torch.Tensor]</code></td>
      <td><p>computed metrics</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">validation_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute loss for a single validation step and log metrics to loggers</span>

<span class="sd">    Args:</span>
<span class="sd">        batch (Tuple[torch.Tensor, ...]): Input batch</span>
<span class="sd">        batch_idx (int): Index of batch</span>

<span class="sd">    Returns:</span>
<span class="sd">        Dict[str, torch.Tensor]: computed metrics</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictor</span><span class="o">.</span><span class="n">get_predictions_and_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">criterion</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">)</span>
    <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compute_metrics</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">val_metrics</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;val&quot;</span>
    <span class="p">)</span>

    <span class="n">metrics</span><span class="p">[</span>
        <span class="s2">&quot;best_score&quot;</span>
    <span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">early_stopping_callback</span><span class="o">.</span><span class="n">best_score</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">metrics</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.TransformerClassificationPLModule" class="doc doc-heading">
        <code>TransformerClassificationPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.TransformerClassificationPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TransformerClassificationPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_TransformerClassification</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-class">



<h2 id="slp.plbind.module.TransformerPLModule" class="doc doc-heading">
        <code>TransformerPLModule</code>



</h2>

    <div class="doc doc-contents ">





  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="slp.plbind.module.TransformerPLModule.__init__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">lr_scheduler</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">hparams</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

</h3>

    <div class="doc doc-contents ">

      <p>Pass arguments through to base class</p>

        <details class="quote">
          <summary>Source code in <code>slp/plbind/module.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Optimizer</span><span class="p">]],</span>
    <span class="n">criterion</span><span class="p">:</span> <span class="n">LossType</span><span class="p">,</span>
    <span class="n">lr_scheduler</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">_LRScheduler</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">hparams</span><span class="p">:</span> <span class="n">Configuration</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">metrics</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">pl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">Metric</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">calculate_perplexity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Pass arguments through to base class&quot;&quot;&quot;</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">TransformerPLModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">optimizer</span><span class="p">,</span>
        <span class="n">criterion</span><span class="p">,</span>
        <span class="n">predictor_cls</span><span class="o">=</span><span class="n">_Transformer</span><span class="p">,</span>
        <span class="n">lr_scheduler</span><span class="o">=</span><span class="n">lr_scheduler</span><span class="p">,</span>
        <span class="n">hparams</span><span class="o">=</span><span class="n">hparams</span><span class="p">,</span>
        <span class="n">metrics</span><span class="o">=</span><span class="n">metrics</span><span class="p">,</span>
        <span class="n">calculate_perplexity</span><span class="o">=</span><span class="n">calculate_perplexity</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>







  </div>

    </div>

  </div>



  <div class="doc doc-object doc-module">

<a id="slp.plbind.trainer"></a>
    <div class="doc doc-contents first">




  <div class="doc doc-children">








  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.trainer.add_optimizer_args" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_optimizer_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Augment parser with optimizer arguments</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parent_parser</code></td>
        <td><code>ArgumentParser</code></td>
        <td><p>Parser created by the user</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ArgumentParser</code></td>
      <td><p>argparse.ArgumentParser: Augmented parser</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/trainer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_optimizer_args</span><span class="p">(</span>
    <span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Augment parser with optimizer arguments</span>

<span class="sd">    Args:</span>
<span class="sd">        parent_parser (argparse.ArgumentParser): Parser created by the user</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.ArgumentParser: Augmented parser</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">parent_parser</span><span class="p">],</span> <span class="n">add_help</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--optimizer&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;optimizer&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span>
            <span class="s2">&quot;Adam&quot;</span><span class="p">,</span>
            <span class="s2">&quot;AdamW&quot;</span><span class="p">,</span>
            <span class="s2">&quot;SGD&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Adadelta&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Adagrad&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Adamax&quot;</span><span class="p">,</span>
            <span class="s2">&quot;ASGD&quot;</span><span class="p">,</span>
            <span class="s2">&quot;RMSprop&quot;</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Which optimizer to use&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;optim.lr&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Learning rate&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--weight-decay&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;optim.weight_decay&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Learning rate&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-scheduler&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;lr_scheduler&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="c1"># type=str,</span>
        <span class="c1"># choices=[&quot;ReduceLROnPlateau&quot;],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use learning rate scheduling. Currently only ReduceLROnPlateau is supported out of the box&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-factor&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;lr_schedule.factor&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Multiplicative factor by which LR is reduced. Used if --lr-scheduler is provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-patience&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;lr_schedule.patience&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of epochs with no improvement after which learning rate will be reduced. Used if --lr-scheduler is provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--lr-cooldown&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;lr_schedule.cooldown&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of epochs to wait before resuming normal operation after lr has been reduced. Used if --lr-scheduler is provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--min-lr&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;lr_schedule.min_lr&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Minimum lr for LR scheduling. Used if --lr-scheduler is provided.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.trainer.add_trainer_args" class="doc doc-heading">
<code class="highlight language-python"><span class="n">add_trainer_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Augment parser with trainer arguments</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>parent_parser</code></td>
        <td><code>ArgumentParser</code></td>
        <td><p>Parser created by the user</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ArgumentParser</code></td>
      <td><p>argparse.ArgumentParser: Augmented parser</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/trainer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">add_trainer_args</span><span class="p">(</span><span class="n">parent_parser</span><span class="p">:</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Augment parser with trainer arguments</span>

<span class="sd">    Args:</span>
<span class="sd">        parent_parser (argparse.ArgumentParser): Parser created by the user</span>

<span class="sd">    Returns:</span>
<span class="sd">        argparse.ArgumentParser: Augmented parser</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">parser</span> <span class="o">=</span> <span class="n">argparse</span><span class="o">.</span><span class="n">ArgumentParser</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="p">[</span><span class="n">parent_parser</span><span class="p">],</span> <span class="n">add_help</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--seed&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Seed for reproducibility&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--config&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;config&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>  <span class="c1"># dir_path,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Path to YAML configuration file&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--experiment-name&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.experiment_name&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Name of the running experiment&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--run-id&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.run_id&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Unique identifier for the current run. If not provided it is inferred from datetime.now()&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--experiment-group&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.experiment_group&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Group of current experiment. Useful when evaluating for different seeds / cross-validation etc.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--experiments-folder&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.experiments_folder&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;experiments&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Top-level folder where experiment results &amp; checkpoints are saved&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--save-top-k&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.save_top_k&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Save checkpoints for top k models&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--patience&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.patience&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of epochs to wait before early stopping&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--wandb-project&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.wandb_project&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Wandb project under which results are saved&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tags&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.tags&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">nargs</span><span class="o">=</span><span class="s2">&quot;*&quot;</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Tags for current run to make results searchable.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--stochastic_weight_avg&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.stochastic_weight_avg&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Use Stochastic weight averaging.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--gpus&quot;</span><span class="p">,</span> <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.gpus&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of GPUs to use&quot;</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--val-interval&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.check_val_every_n_epoch&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Run validation every n epochs&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--clip-grad-norm&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.gradient_clip_val&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">float</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Clip gradients with ||grad(w)|| &gt;= args.clip_grad_norm&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--epochs&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.max_epochs&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum number of training epochs&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--num-nodes&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.num_nodes&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Number of nodes to run&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--steps&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.max_steps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Maximum number of training steps&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--tbtt_steps&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.truncated_bptt_steps&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">int</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Truncated Back-propagation-through-time steps.&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--debug&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;debug&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If true, we run a full run on a small subset of the input data and overfit 10 training batches&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--offline&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.force_wandb_offline&quot;</span><span class="p">,</span>
        <span class="n">action</span><span class="o">=</span><span class="s2">&quot;store_true&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;If true, forces offline execution of wandb logger&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--early-stop-on&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.early_stop_on&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Metric for early stopping&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">parser</span><span class="o">.</span><span class="n">add_argument</span><span class="p">(</span>
        <span class="s2">&quot;--early-stop-mode&quot;</span><span class="p">,</span>
        <span class="n">dest</span><span class="o">=</span><span class="s2">&quot;trainer.early_stop_mode&quot;</span><span class="p">,</span>
        <span class="nb">type</span><span class="o">=</span><span class="nb">str</span><span class="p">,</span>
        <span class="n">choices</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="s2">&quot;max&quot;</span><span class="p">],</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span>
        <span class="n">help</span><span class="o">=</span><span class="s2">&quot;Minimize or maximize early stopping metric&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">parser</span>
</code></pre></div>
        </details>
    </div>

  </div>




  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.trainer.make_trainer" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_trainer</span><span class="p">(</span><span class="n">experiment_name</span><span class="o">=</span><span class="s1">&#39;experiment&#39;</span><span class="p">,</span> <span class="n">experiment_description</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">run_id</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">experiment_group</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">experiments_folder</span><span class="o">=</span><span class="s1">&#39;experiments&#39;</span><span class="p">,</span> <span class="n">save_top_k</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">wandb_project</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">wandb_user</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">force_wandb_offline</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stochastic_weight_avg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">auto_scale_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">num_nodes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">truncated_bptt_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">fast_dev_run</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">overfit_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">terminate_on_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">profiler</span><span class="o">=</span><span class="s1">&#39;simple&#39;</span><span class="p">,</span> <span class="n">early_stop_on</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">early_stop_mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Configure trainer with preferred defaults</p>
<ul>
<li>Experiment folder and run_id configured (based on datetime.now())</li>
<li>Wandb and CSV loggers run by default</li>
<li>Wandb configured to save code and checkpoints</li>
<li>Wandb configured in online mode except if no internet connection is available</li>
<li>Early stopping on best validation loss is configured by default</li>
<li>Checkpointing on best validation loss is configured by default
*</li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>experiment_name</code></td>
        <td><code>str</code></td>
        <td><p>Experiment name. Defaults to "experiment".</p></td>
        <td><code>&#39;experiment&#39;</code></td>
      </tr>
      <tr>
        <td><code>experiment_description</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Detailed description of the experiment. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>run_id</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Unique run_id. Defaults to datetime.now(). Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>experiment_group</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Group experiments over multiple runs. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>experiments_folder</code></td>
        <td><code>str</code></td>
        <td><p>Folder to save outputs. Defaults to "experiments".</p></td>
        <td><code>&#39;experiments&#39;</code></td>
      </tr>
      <tr>
        <td><code>save_top_k</code></td>
        <td><code>int</code></td>
        <td><p>Save top k checkpoints. Defaults to 3.</p></td>
        <td><code>3</code></td>
      </tr>
      <tr>
        <td><code>patience</code></td>
        <td><code>int</code></td>
        <td><p>Patience for early stopping. Defaults to 3.</p></td>
        <td><code>3</code></td>
      </tr>
      <tr>
        <td><code>wandb_project</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Wandb project to save the experiment. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>wandb_user</code></td>
        <td><code>Optional[str]</code></td>
        <td><p>Wandb username. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>force_wandb_offline</code></td>
        <td><code>bool</code></td>
        <td><p>Force offline execution of wandb</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>tags</code></td>
        <td><code>Optional[Sequence]</code></td>
        <td><p>Additional tags to attach to the experiment. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>stochastic_weight_avg</code></td>
        <td><code>bool</code></td>
        <td><p>Use stochastic weight averaging. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>auto_scale_batch_size</code></td>
        <td><code>bool</code></td>
        <td><p>Find optimal batch size for the available resources when running
    trainer.tune(). Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>gpus</code></td>
        <td><code>int</code></td>
        <td><p>number of GPUs to use. Defaults to 0.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>check_val_every_n_epoch</code></td>
        <td><code>int</code></td>
        <td><p>Run validation every n epochs. Defaults to 1.</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>gradient_clip_val</code></td>
        <td><code>float</code></td>
        <td><p>Clip gradient norm value. Defaults to 0 (no clipping).</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>precision</code></td>
        <td><code>int</code></td>
        <td><p>Floating point precision. Defaults to 32.</p></td>
        <td><code>32</code></td>
      </tr>
      <tr>
        <td><code>num_nodes</code></td>
        <td><code>int</code></td>
        <td><p>Number of nodes to run on</p></td>
        <td><code>1</code></td>
      </tr>
      <tr>
        <td><code>max_epochs</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Maximum number of epochs for training. Defaults to 100.</p></td>
        <td><code>100</code></td>
      </tr>
      <tr>
        <td><code>max_steps</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Maximum number of steps for training. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>truncated_bptt_steps</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Truncated back prop breaks performs backprop every k steps of much longer
    sequence. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>fast_dev_run</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Run training on a small number of  batches for debugging. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>overfit_batches</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Try to overfit a small number of batches for debugging. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>terminate_on_nan</code></td>
        <td><code>bool</code></td>
        <td><p>Terminate on NaN gradients. Warning this makes training slow. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>profiler</code></td>
        <td><code>Union[pytorch_lightning.profiler.profilers.BaseProfiler, bool, str]</code></td>
        <td><p>Use profiler to track execution times of each function</p></td>
        <td><code>&#39;simple&#39;</code></td>
      </tr>
      <tr>
        <td><code>early_stop_on</code></td>
        <td><code>str</code></td>
        <td><p>metric for early stopping</p></td>
        <td><code>&#39;val_loss&#39;</code></td>
      </tr>
      <tr>
        <td><code>early_stop_mode</code></td>
        <td><code>str</code></td>
        <td><p>"min" or "max"</p></td>
        <td><code>&#39;min&#39;</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Trainer</code></td>
      <td><p>pl.Trainer: Configured trainer</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/trainer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_trainer</span><span class="p">(</span>
    <span class="n">experiment_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiment&quot;</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">run_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_group</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiments_folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experiments&quot;</span><span class="p">,</span>
    <span class="n">save_top_k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">wandb_project</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">wandb_user</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">force_wandb_offline</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">tags</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Sequence</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">stochastic_weight_avg</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">auto_scale_batch_size</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">gpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">check_val_every_n_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">gradient_clip_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">num_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">truncated_bptt_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">fast_dev_run</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">overfit_batches</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">terminate_on_nan</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># Be careful this makes training very slow for large models</span>
    <span class="n">profiler</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pl</span><span class="o">.</span><span class="n">profiler</span><span class="o">.</span><span class="n">BaseProfiler</span><span class="p">,</span> <span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="s2">&quot;simple&quot;</span><span class="p">,</span>
    <span class="n">early_stop_on</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="n">early_stop_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configure trainer with preferred defaults</span>

<span class="sd">    * Experiment folder and run_id configured (based on datetime.now())</span>
<span class="sd">    * Wandb and CSV loggers run by default</span>
<span class="sd">    * Wandb configured to save code and checkpoints</span>
<span class="sd">    * Wandb configured in online mode except if no internet connection is available</span>
<span class="sd">    * Early stopping on best validation loss is configured by default</span>
<span class="sd">    * Checkpointing on best validation loss is configured by default</span>
<span class="sd">    *</span>

<span class="sd">    Args:</span>
<span class="sd">        experiment_name (str, optional): Experiment name. Defaults to &quot;experiment&quot;.</span>
<span class="sd">        experiment_description (Optional[str], optional): Detailed description of the experiment. Defaults to None.</span>
<span class="sd">        run_id (Optional[str], optional): Unique run_id. Defaults to datetime.now(). Defaults to None.</span>
<span class="sd">        experiment_group (Optional[str], optional): Group experiments over multiple runs. Defaults to None.</span>
<span class="sd">        experiments_folder (str, optional): Folder to save outputs. Defaults to &quot;experiments&quot;.</span>
<span class="sd">        save_top_k (int, optional): Save top k checkpoints. Defaults to 3.</span>
<span class="sd">        patience (int, optional): Patience for early stopping. Defaults to 3.</span>
<span class="sd">        wandb_project (Optional[str], optional): Wandb project to save the experiment. Defaults to None.</span>
<span class="sd">        wandb_user (Optional[str], optional): Wandb username. Defaults to None.</span>
<span class="sd">        force_wandb_offline (bool): Force offline execution of wandb</span>
<span class="sd">        tags (Optional[Sequence], optional): Additional tags to attach to the experiment. Defaults to None.</span>
<span class="sd">        stochastic_weight_avg (bool, optional): Use stochastic weight averaging. Defaults to False.</span>
<span class="sd">        auto_scale_batch_size (bool, optional): Find optimal batch size for the available resources when running</span>
<span class="sd">                trainer.tune(). Defaults to False.</span>
<span class="sd">        gpus (int, optional): number of GPUs to use. Defaults to 0.</span>
<span class="sd">        check_val_every_n_epoch (int, optional): Run validation every n epochs. Defaults to 1.</span>
<span class="sd">        gradient_clip_val (float, optional): Clip gradient norm value. Defaults to 0 (no clipping).</span>
<span class="sd">        precision (int, optional): Floating point precision. Defaults to 32.</span>
<span class="sd">        num_nodes (int): Number of nodes to run on</span>
<span class="sd">        max_epochs (Optional[int], optional): Maximum number of epochs for training. Defaults to 100.</span>
<span class="sd">        max_steps (Optional[int], optional): Maximum number of steps for training. Defaults to None.</span>
<span class="sd">        truncated_bptt_steps (Optional[int], optional): Truncated back prop breaks performs backprop every k steps of much longer</span>
<span class="sd">                sequence. Defaults to None.</span>
<span class="sd">        fast_dev_run (Optional[int], optional): Run training on a small number of  batches for debugging. Defaults to None.</span>
<span class="sd">        overfit_batches (Optional[int], optional): Try to overfit a small number of batches for debugging. Defaults to None.</span>
<span class="sd">        terminate_on_nan (bool, optional): Terminate on NaN gradients. Warning this makes training slow. Defaults to False.</span>
<span class="sd">        profiler (Optional[Union[pl.profiler.BaseProfiler, bool, str]]): Use profiler to track execution times of each function</span>
<span class="sd">        early_stop_on (str): metric for early stopping</span>
<span class="sd">        early_stop_mode (str): &quot;min&quot; or &quot;max&quot;</span>

<span class="sd">    Returns:</span>
<span class="sd">        pl.Trainer: Configured trainer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">overfit_batches</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">overfit_batches</span><span class="o">=</span><span class="n">overfit_batches</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="n">gpus</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">trainer</span>

    <span class="k">if</span> <span class="n">fast_dev_run</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span><span class="n">fast_dev_run</span><span class="o">=</span><span class="n">fast_dev_run</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="n">gpus</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">trainer</span>

    <span class="n">logging_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">experiments_folder</span><span class="p">,</span> <span class="n">experiment_name</span><span class="p">)</span>
    <span class="n">safe_mkdirs</span><span class="p">(</span><span class="n">logging_dir</span><span class="p">)</span>

    <span class="n">run_id</span> <span class="o">=</span> <span class="n">run_id</span> <span class="k">if</span> <span class="n">run_id</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">date_fname</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">run_id</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">logging_dir</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;The run id you provided </span><span class="si">{run_id}</span><span class="s2"> already exists in </span><span class="si">{logging_dir}</span><span class="s2">&quot;</span>
        <span class="p">)</span>
        <span class="n">run_id</span> <span class="o">=</span> <span class="n">date_fname</span><span class="p">()</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Setting run_id=</span><span class="si">{run_id}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">checkpoint_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">logging_dir</span><span class="p">,</span> <span class="n">run_id</span><span class="p">,</span> <span class="s2">&quot;checkpoints&quot;</span><span class="p">)</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Logs will be saved in </span><span class="si">{</span><span class="n">logging_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Logs will be saved in </span><span class="si">{</span><span class="n">checkpoint_dir</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">wandb_project</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">wandb_project</span> <span class="o">=</span> <span class="n">experiment_name</span>

    <span class="n">connected</span> <span class="o">=</span> <span class="n">has_internet_connection</span><span class="p">()</span>
    <span class="n">offline_run</span> <span class="o">=</span> <span class="n">force_wandb_offline</span> <span class="ow">or</span> <span class="ow">not</span> <span class="n">connected</span>

    <span class="n">loggers</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">loggers</span><span class="o">.</span><span class="n">CSVLogger</span><span class="p">(</span><span class="n">logging_dir</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;csv_logs&quot;</span><span class="p">,</span> <span class="n">version</span><span class="o">=</span><span class="n">run_id</span><span class="p">),</span>
        <span class="n">FixedWandbLogger</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
            <span class="n">name</span><span class="o">=</span><span class="n">experiment_name</span><span class="p">,</span>
            <span class="n">project</span><span class="o">=</span><span class="n">wandb_project</span><span class="p">,</span>
            <span class="n">anonymous</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">save_dir</span><span class="o">=</span><span class="n">logging_dir</span><span class="p">,</span>
            <span class="n">version</span><span class="o">=</span><span class="n">run_id</span><span class="p">,</span>
            <span class="n">save_code</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">checkpoint_dir</span><span class="o">=</span><span class="n">checkpoint_dir</span><span class="p">,</span>
            <span class="n">offline</span><span class="o">=</span><span class="n">offline_run</span><span class="p">,</span>
            <span class="n">log_model</span><span class="o">=</span><span class="ow">not</span> <span class="n">offline_run</span><span class="p">,</span>
            <span class="n">entity</span><span class="o">=</span><span class="n">wandb_user</span><span class="p">,</span>
            <span class="n">group</span><span class="o">=</span><span class="n">experiment_group</span><span class="p">,</span>
            <span class="n">notes</span><span class="o">=</span><span class="n">experiment_description</span><span class="p">,</span>
            <span class="n">tags</span><span class="o">=</span><span class="n">tags</span><span class="p">,</span>
        <span class="p">),</span>
    <span class="p">]</span>

    <span class="k">if</span> <span class="n">gpus</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">del</span> <span class="n">loggers</span><span class="p">[</span>
            <span class="mi">1</span>
        <span class="p">]</span>  <span class="c1"># https://github.com/PyTorchLightning/pytorch-lightning/issues/6106</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Configured wandb and CSV loggers.&quot;</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Wandb configured to run </span><span class="si">{</span><span class="n">experiment_name</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span><span class="s2"> in project </span><span class="si">{</span><span class="n">wandb_project</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">connected</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results will be stored online.&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Results will be stored offline due to bad internet connection.&quot;</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;If you want to upload your results later run</span><span class="se">\n\t</span><span class="s2"> wandb sync </span><span class="si">{</span><span class="n">logging_dir</span><span class="si">}</span><span class="s2">/wandb/run-</span><span class="si">{</span><span class="n">run_id</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">experiment_description</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Experiment verbose description:</span><span class="se">\n</span><span class="si">{</span><span class="n">experiment_description</span><span class="si">}</span><span class="se">\n\n</span><span class="s2">Tags:</span><span class="si">{</span><span class="s1">&#39;n/a&#39;</span> <span class="k">if</span> <span class="n">tags</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">tags</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">EarlyStoppingWithLogs</span><span class="p">(</span>
            <span class="n">monitor</span><span class="o">=</span><span class="n">early_stop_on</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">early_stop_mode</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">ModelCheckpoint</span><span class="p">(</span>
            <span class="n">dirpath</span><span class="o">=</span><span class="n">checkpoint_dir</span><span class="p">,</span>
            <span class="n">filename</span><span class="o">=</span><span class="s2">&quot;</span><span class="si">{epoch}</span><span class="s2">-</span><span class="si">{val_loss:.2f}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">monitor</span><span class="o">=</span><span class="n">early_stop_on</span><span class="p">,</span>
            <span class="n">save_top_k</span><span class="o">=</span><span class="n">save_top_k</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">early_stop_mode</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateMonitor</span><span class="p">(</span><span class="n">logging_interval</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Configured Early stopping and Model checkpointing to track val_loss&quot;</span><span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">default_root_dir</span><span class="o">=</span><span class="n">logging_dir</span><span class="p">,</span>
        <span class="n">gpus</span><span class="o">=</span><span class="n">gpus</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">logger</span><span class="o">=</span><span class="n">loggers</span><span class="p">,</span>
        <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="n">check_val_every_n_epoch</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">auto_scale_batch_size</span><span class="o">=</span><span class="n">auto_scale_batch_size</span><span class="p">,</span>
        <span class="n">stochastic_weight_avg</span><span class="o">=</span><span class="n">stochastic_weight_avg</span><span class="p">,</span>
        <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
        <span class="n">truncated_bptt_steps</span><span class="o">=</span><span class="n">truncated_bptt_steps</span><span class="p">,</span>
        <span class="n">terminate_on_nan</span><span class="o">=</span><span class="n">terminate_on_nan</span><span class="p">,</span>
        <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">profiler</span><span class="o">=</span><span class="n">profiler</span><span class="p">,</span>
        <span class="n">num_nodes</span><span class="o">=</span><span class="n">num_nodes</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">trainer</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.trainer.make_trainer_for_ray_tune" class="doc doc-heading">
<code class="highlight language-python"><span class="n">make_trainer_for_ray_tune</span><span class="p">(</span><span class="n">patience</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stochastic_weight_avg</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">gpus</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">gradient_clip_val</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">truncated_bptt_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">terminate_on_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">early_stop_on</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">early_stop_mode</span><span class="o">=</span><span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">metrics_map</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>Configure trainer with preferred defaults</p>
<ul>
<li>Early stopping on best validation loss is configured by default</li>
<li>Ray tune callback configured</li>
</ul>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>patience</code></td>
        <td><code>int</code></td>
        <td><p>Patience for early stopping. Defaults to 3.</p></td>
        <td><code>3</code></td>
      </tr>
      <tr>
        <td><code>stochastic_weight_avg</code></td>
        <td><code>bool</code></td>
        <td><p>Use stochastic weight averaging. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>gpus</code></td>
        <td><code>int</code></td>
        <td><p>number of GPUs to use. Defaults to 0.</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>gradient_clip_val</code></td>
        <td><code>float</code></td>
        <td><p>Clip gradient norm value. Defaults to 0 (no clipping).</p></td>
        <td><code>0</code></td>
      </tr>
      <tr>
        <td><code>precision</code></td>
        <td><code>int</code></td>
        <td><p>Floating point precision. Defaults to 32.</p></td>
        <td><code>32</code></td>
      </tr>
      <tr>
        <td><code>max_epochs</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Maximum number of epochs for training. Defaults to 100.</p></td>
        <td><code>100</code></td>
      </tr>
      <tr>
        <td><code>max_steps</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Maximum number of steps for training. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>truncated_bptt_steps</code></td>
        <td><code>Optional[int]</code></td>
        <td><p>Truncated back prop breaks performs backprop every k steps of much longer
    sequence. Defaults to None.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>terminate_on_nan</code></td>
        <td><code>bool</code></td>
        <td><p>Terminate on NaN gradients. Warning this makes training slow. Defaults to False.</p></td>
        <td><code>False</code></td>
      </tr>
      <tr>
        <td><code>early_stop_on</code></td>
        <td><code>str</code></td>
        <td><p>metric for early stopping</p></td>
        <td><code>&#39;val_loss&#39;</code></td>
      </tr>
      <tr>
        <td><code>early_stop_mode</code></td>
        <td><code>str</code></td>
        <td><p>"min" or "max"</p></td>
        <td><code>&#39;min&#39;</code></td>
      </tr>
      <tr>
        <td><code>metrics_map</code></td>
        <td><code>Optional[Dict[str, str]]</code></td>
        <td><p>The mapping from pytorch lightning logged metrics
to ray tune metrics. The --tune-metric argument should be one of the keys of this
mapping</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>extra_kwargs</code></td>
        <td><code>kwargs</code></td>
        <td><p>Ignored. We use it so that we are able to pass the same config
object as in make_trainer</p></td>
        <td><code>{}</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Trainer</code></td>
      <td><p>pl.Trainer: Configured trainer</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/trainer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_trainer_for_ray_tune</span><span class="p">(</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
    <span class="n">stochastic_weight_avg</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">gpus</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">gradient_clip_val</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">precision</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">max_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">truncated_bptt_steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">terminate_on_nan</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>  <span class="c1"># Be careful this makes training very slow for large models</span>
    <span class="n">early_stop_on</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;val_loss&quot;</span><span class="p">,</span>
    <span class="n">early_stop_mode</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;min&quot;</span><span class="p">,</span>
    <span class="n">metrics_map</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">extra_kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Configure trainer with preferred defaults</span>

<span class="sd">    * Early stopping on best validation loss is configured by default</span>
<span class="sd">    * Ray tune callback configured</span>

<span class="sd">    Args:</span>
<span class="sd">        patience (int, optional): Patience for early stopping. Defaults to 3.</span>
<span class="sd">        stochastic_weight_avg (bool, optional): Use stochastic weight averaging. Defaults to False.</span>
<span class="sd">        gpus (int, optional): number of GPUs to use. Defaults to 0.</span>
<span class="sd">        gradient_clip_val (float, optional): Clip gradient norm value. Defaults to 0 (no clipping).</span>
<span class="sd">        precision (int, optional): Floating point precision. Defaults to 32.</span>
<span class="sd">        max_epochs (Optional[int], optional): Maximum number of epochs for training. Defaults to 100.</span>
<span class="sd">        max_steps (Optional[int], optional): Maximum number of steps for training. Defaults to None.</span>
<span class="sd">        truncated_bptt_steps (Optional[int], optional): Truncated back prop breaks performs backprop every k steps of much longer</span>
<span class="sd">                sequence. Defaults to None.</span>
<span class="sd">        terminate_on_nan (bool, optional): Terminate on NaN gradients. Warning this makes training slow. Defaults to False.</span>
<span class="sd">        early_stop_on (str): metric for early stopping</span>
<span class="sd">        early_stop_mode (str): &quot;min&quot; or &quot;max&quot;</span>
<span class="sd">        metrics_map (Optional[Dict[str, str]]): The mapping from pytorch lightning logged metrics</span>
<span class="sd">            to ray tune metrics. The --tune-metric argument should be one of the keys of this</span>
<span class="sd">            mapping</span>
<span class="sd">        extra_kwargs (kwargs): Ignored. We use it so that we are able to pass the same config</span>
<span class="sd">            object as in make_trainer</span>
<span class="sd">    Returns:</span>
<span class="sd">        pl.Trainer: Configured trainer</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">metrics_map</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Need to pass metrics for TuneReportCallback&quot;</span><span class="p">)</span>

    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">EarlyStoppingWithLogs</span><span class="p">(</span>
            <span class="n">monitor</span><span class="o">=</span><span class="n">early_stop_on</span><span class="p">,</span>
            <span class="n">mode</span><span class="o">=</span><span class="n">early_stop_mode</span><span class="p">,</span>
            <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">),</span>
        <span class="n">TuneReportCallback</span><span class="p">(</span><span class="n">metrics_map</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s2">&quot;validation_end&quot;</span><span class="p">),</span>
        <span class="n">pl</span><span class="o">.</span><span class="n">callbacks</span><span class="o">.</span><span class="n">LearningRateMonitor</span><span class="p">(</span><span class="n">logging_interval</span><span class="o">=</span><span class="s2">&quot;step&quot;</span><span class="p">),</span>
    <span class="p">]</span>

    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Configured Early stopping to track val_loss&quot;</span><span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">(</span>
        <span class="n">gpus</span><span class="o">=</span><span class="n">gpus</span><span class="p">,</span>
        <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs</span><span class="p">,</span>
        <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">logger</span><span class="o">=</span><span class="p">[],</span>
        <span class="n">check_val_every_n_epoch</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">gradient_clip_val</span><span class="o">=</span><span class="n">gradient_clip_val</span><span class="p">,</span>
        <span class="n">stochastic_weight_avg</span><span class="o">=</span><span class="n">stochastic_weight_avg</span><span class="p">,</span>
        <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
        <span class="n">truncated_bptt_steps</span><span class="o">=</span><span class="n">truncated_bptt_steps</span><span class="p">,</span>
        <span class="n">terminate_on_nan</span><span class="o">=</span><span class="n">terminate_on_nan</span><span class="p">,</span>
        <span class="n">progress_bar_refresh_rate</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">num_sanity_val_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">auto_scale_batch_size</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">trainer</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-function">



<h2 id="slp.plbind.trainer.watch_model" class="doc doc-heading">
<code class="highlight language-python"><span class="n">watch_model</span><span class="p">(</span><span class="n">trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span></code>


</h2>

    <div class="doc doc-contents ">

      <p>If wandb logger is configured track gradient and weight norms</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>trainer</code></td>
        <td><code>Trainer</code></td>
        <td><p>Trainer</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>model</code></td>
        <td><code>Module</code></td>
        <td><p>Module to watch</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>slp/plbind/trainer.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">watch_model</span><span class="p">(</span><span class="n">trainer</span><span class="p">:</span> <span class="n">pl</span><span class="o">.</span><span class="n">Trainer</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;If wandb logger is configured track gradient and weight norms</span>

<span class="sd">    Args:</span>
<span class="sd">        trainer (pl.Trainer): Trainer</span>
<span class="sd">        model (nn.Module): Module to watch</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">trainer</span><span class="o">.</span><span class="n">num_gpus</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">return</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Tracking model weights &amp; gradients in wandb.&quot;</span><span class="p">)</span>

                <span class="k">break</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="k">pass</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">trainer</span><span class="o">.</span><span class="n">logger</span><span class="o">.</span><span class="n">experiment</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">)</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Tracking model weights &amp; gradients in wandb.&quot;</span><span class="p">)</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
</code></pre></div>
        </details>
    </div>

  </div>






  </div>

    </div>

  </div>
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="Footer">
      
        <a href="../data-utils/" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Data manipulation
            </div>
          </div>
        </a>
      
      
        <a href="../modules/" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Generic Modules
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        Made with
        <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
          Material for MkDocs
        </a>
        
      </div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "..", "features": [], "translations": {"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.term.missing": "Missing"}, "search": "../assets/javascripts/workers/search.fb4a9340.min.js", "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.5cf3e710.min.js"></script>
      
        <script src="../javascripts/config.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>